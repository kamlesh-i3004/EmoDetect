<!-- EmoDetect: Modern README -->

<p align="center">
  <img src="https://img.shields.io/github/stars/kamlesh-i3004/EmoDetect?style=social" alt="GitHub Stars" />
  <img src="https://img.shields.io/github/forks/kamlesh-i3004/EmoDetect?style=social" alt="GitHub Forks" />
  <img src="https://img.shields.io/github/issues/kamlesh-i3004/EmoDetect" alt="GitHub Issues" />
  <img src="https://img.shields.io/github/license/kamlesh-i3004/EmoDetect" alt="License" />
</p>

<h1 align="center">ğŸ¤ EmoDetect: Real-Time Emotion Detection Through Voice</h1>
<p align="center">
  <b>Classifies emotions from voice using Machine Learning.<br>Supports real-time & static audio, high accuracy, and easy integration!</b>
</p>

---

## ğŸš€ Quick Start

```bash
pip install numpy pandas tensorflow matplotlib seaborn librosa tqdm pickle scikit-learn sounddevice
```
> **For Jupyter Notebook:** Use `!` before `pip`<br>
> **For VSCode:** Paste in the terminal (see image below)

<p align="center">
  <img src="https://github.com/user-attachments/assets/249462b3-ed29-4ce4-8daa-976d025f7bce" width="450" />
</p>

---

## ğŸ§© Features

- ğŸ™ï¸ **Real-Time Audio Processing:** Live emotion prediction from microphone input
- ğŸ“‚ **Static Audio Testing:** Evaluate with pre-recorded files
- ğŸ˜„ **Multiple Emotion Classes:** Happy, Sad, Angry, Neutral, and more!
- ğŸ”¥ **High Accuracy:** 93-95% in controlled environments

---

## ğŸ—’ï¸ Documentation & Resources

<p align="center">
  <a href="https://github.com/kamlesh-i3004/EmoDetect/blob/main/Documentation.md">
    <img src="https://img.shields.io/badge/View-Documentation-blue?style=for-the-badge" alt="Documentation"/>
  </a>
  <a href="https://github.com/kamlesh-i3004/EmoDetect/issues">
    <img src="https://img.shields.io/badge/Report%20Issue-GitHub-red?style=for-the-badge" alt="Issues"/>
  </a>
  <a href="https://github.com/kamlesh-i3004/EmoDetect/pulls">
    <img src="https://img.shields.io/badge/Open%20Pull%20Request-green?style=for-the-badge" alt="Pull Requests"/>
  </a>
</p>

---

## ğŸ¯ Project Goal

Develop a robust emotion detection system for both real-time and static audio, laying the foundation for real-world applications such as virtual assistants, call centers, and more.

---

## ğŸ¤ Contributing

Pull requests, suggestions, and feedback are welcome!  
See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

This project is licensed under the terms of the [MIT License](LICENSE).

---

<p align="center">
  <b>Enjoy EmoDetect! â­ If you like it, star the repo!</b>
</p>
